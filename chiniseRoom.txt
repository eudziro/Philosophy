Аргумент китайской комнаты Дж.Серла. Сильный и Слабый ИИ.
Критика мысленного эксперимента Дж.Серла. Основные контраргументы.

Аргумент китайской комнаты Джорджа Серла: в изолированной комнате находится
Дж.Серл, который не знает китайский язык, однако на каждые входные данные у него
есть иструкция как действовать. Наблюдатель, который знает китайские иероглифы,
передает в комнату иероглифы с вопросами, и ожидает получить осознанный ответ.
Фактически, инструкция – это есть компьютерный алгоритм, а Серл просто выполняет
алгоритм также, как его бы исполнил компьютер.

В такой ситуации наблюдатель может отправить в комнату любой осмысленный вопрос,
(например:  – Какой цвет вам нравится больше? ) и получить такой же осмысленный
ответ (например: – Синий), как при разговоре с человеком, который свободно владеет
китайскими иероглифами.

Таким образом, Серл заключает, что такая система может пройти тест Тьюринга, а значит
тест Тьюринга не является адекватной проверкой мыслительных способностей.
Доводы Сёрла направлены на критику позиции так называемого «сильного»
искусственного интеллекта, согласно которой компьютеры с соответствующей
программой на самом деле могут понимать естественный язык, а также обладать
другими ментальными способностями, свойственными людям.

Предпосылки:

Мельница Лейбница – Лейбниц предлагает представить машину размером с мельницу,
которая симулирует чувства, мысли и восприятие. И если зайти внутрь такой машины,
то ни одна из движущихся частей, обеспечивающих её работу, не будет являться сознанием
или объяснением восприятия. Так Лейбниц пытался показать, что одних физических состояний
недостаточно для функционирования сознания

Бумажная машина Тьюринга» — машинный алгоритм для игры в шахматы, придуманный
Аланом Тьюрингом в 1951 году, где в качестве машины-исполнителя выступал человек.
При этом человеку не нужно было знать, как играть в шахматы, а нужно было просто
исполнять алгоритм, на основе входных данных о ходе соперника
(например, «при ходе противника N передвиньте ферзя на B7»). Тьюринг считал,
что компьютеры будут способны к поддержанию беседы на человеческом языке, для
этого он и разработал то, что сейчас называется тестом Тьюринга.

«Китайская нация» — мысленный эксперимент, предложенный Недом Блоком в 1978 году
для опровержения функционализма. Эксперимент Блока схож с «Китайской комнатой»,
однако Блок предлагает использовать множество китайцев, каждый из которых бы
эмулировал нейрон искусственного мозга. В такой системе каждый китаец имел бы
телефон и список номеров других китайцев. В зависимости от того, когда зазвонил
телефон конкретного китайца, он бы звонил кому-либо из своего списка. При этом
передача сообщения по телефону не требуется, необходим лишь только факт звонка
(так же происходит взаимодействие между нейронами). Тогда, если в такой системе
создать функциональное состояние, которое появляется при восприятии боли, вся
«Китайская нация» окажется в состоянии боли, при этом ни один из китайцев не
будет эту боль чувствовать. Это применимо к любым ментальным состояниям и чувствам.

Критика

Аргумент о системе
Некоторые критики считают, что тест Тьюринга выдержал не человек в комнате, а система,
состоящая из комнаты, книги правил и человека. Сёрл, по их мнению, отвлекает
внимание от этого факта, скрывая логические ошибки и концентрируясь на одном из
компонентов системы, выполняющем в данном случае чисто механическую работу.
Система из книги правил, человека и комнаты, по их мнению, является разумной и
понимает китайский язык. В качестве контраргумента Сёрл предлагает заставить
человека запомнить формальные правила ответов для системы. По мнению философа,
система, которая теперь будет состоять только из человека, всё равно не сможет
понять китайский язык.

Другие умы
Ещё одно возражение к «китайской комнате» основано на том, что мы определяем,
понимает ли человек китайские иероглифы, лишь по его поведению. Если компьютер
ведёт себя так же, как человек, владеющий китайской письменностью, то тогда
нам следует полагать, что и компьютер её понимает. Таким критикам Сёрл отвечал,
что суть аргумента не в том, откуда мы знаем, что у других людей есть ментальные
состояния, а в том, что́ есть эти ментальные состояния. С точки зрения Сёрла,
ментальные состояния не могут быть определены как просто вычислительный процесс
и его вывод, поскольку для этого не требуется ментальное состояние.

Что такое думать? И как понимать вопрос: думает ли машина?
Думать – в понимании человека, обрабатывать информацию и выдавать логический ответ.
Тест Тьюринга быть создан Тьюригом, чтобы понять может ли машина думать.
Рассуждение о том, что чат-боты, никогда не научатся думать, является ложным,
потому что все известные чат-боты прошли тест Тьюринга.
